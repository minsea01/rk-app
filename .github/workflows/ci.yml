name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop, claude/** ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: '3.10'

jobs:
  # Python linting and formatting
  python-quality:
    name: Python Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black pylint flake8 isort mypy
          pip install -r requirements-dev.txt

      - name: Check code formatting with black
        run: black --check apps/ tools/ tests/

      - name: Lint with pylint
        run: pylint apps/ tools/ --fail-under=8.0 || true

      - name: Lint with flake8
        run: flake8 apps/ tools/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Check import sorting
        run: isort --check-only apps/ tools/ tests/

      - name: Type check with mypy
        run: mypy apps/config.py apps/exceptions.py apps/logger.py --ignore-missing-imports || true

  # Python unit tests
  python-tests:
    name: Python Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run tests with pytest
        run: |
          pytest tests/unit/ -v --cov=apps --cov=tools --cov-report=xml --cov-report=html

      - name: Upload coverage to Codecov
        if: matrix.python-version == '3.10'
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Archive coverage report
        if: matrix.python-version == '3.10'
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: htmlcov/

  # C++ build and test
  cpp-build:
    name: C++ Build and Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake g++ libopencv-dev libyaml-cpp-dev

      - name: Configure CMake (x86)
        run: cmake --preset x86-release

      - name: Build
        run: cmake --build build/x86 --parallel $(nproc)

      - name: Run C++ tests
        run: |
          cd build/x86
          ctest --output-on-failure

  # Cross-compilation for ARM64
  arm64-cross-compile:
    name: ARM64 Cross-compilation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install cross-compilation toolchain
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc-aarch64-linux-gnu g++-aarch64-linux-gnu

      - name: Configure CMake (ARM64)
        run: cmake --preset arm64-release

      - name: Build ARM64
        run: cmake --build build/arm64 --parallel $(nproc)

      - name: Archive ARM64 binaries
        uses: actions/upload-artifact@v3
        with:
          name: arm64-binaries
          path: out/arm64/

  # Model conversion validation
  model-validation:
    name: Model Conversion Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Validate ONNX models
        run: |
          python3 -c "import onnx; onnx.checker.check_model('artifacts/models/best.onnx')"

      - name: Test ONNX inference
        run: |
          python3 -c "
          import onnxruntime as ort
          import numpy as np
          sess = ort.InferenceSession('artifacts/models/best.onnx', providers=['CPUExecutionProvider'])
          dummy = np.random.randn(1, 3, 640, 640).astype(np.float32)
          output = sess.run(None, {sess.get_inputs()[0].name: dummy})
          print(f'âœ“ ONNX inference test passed, output shape: {output[0].shape}')
          "

  # Security scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  # Documentation build
  docs-build:
    name: Build Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install pdoc3 mkdocs mkdocs-material

      - name: Generate API documentation
        run: |
          pdoc --html --output-dir docs/api apps tools

      - name: Build MkDocs site
        run: |
          if [ -f mkdocs.yml ]; then mkdocs build; fi

      - name: Upload documentation
        uses: actions/upload-artifact@v3
        with:
          name: documentation
          path: docs/api/

  # Performance benchmarks
  benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest-benchmark

      - name: Run performance benchmarks
        run: |
          pytest tests/benchmarks/ -v --benchmark-only --benchmark-json=benchmark.json || true

      - name: Store benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: benchmark.json

  # Integration status check
  ci-success:
    name: CI Success
    needs: [python-quality, python-tests, cpp-build, arm64-cross-compile, model-validation]
    runs-on: ubuntu-latest
    steps:
      - name: Success
        run: echo "All CI checks passed!"
