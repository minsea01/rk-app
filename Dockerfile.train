# GPU Training Dockerfile for YOLO Fine-tuning
# Supports NVIDIA GPU with CUDA 11.7
# Target: CityPersons fine-tuning to achieve â‰¥90% mAP@0.5

FROM nvidia/cuda:11.7.0-cudnn8-devel-ubuntu22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=Asia/Shanghai

# Configure APT mirror for faster download in China
RUN sed -i 's|http://archive.ubuntu.com|http://mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list && \
    apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    python3-dev \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    vim \
    htop \
    && rm -rf /var/lib/apt/lists/*

# Create working directory
WORKDIR /workspace

# Configure pip mirror for faster download
RUN pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && \
    pip3 config set global.trusted-host pypi.tuna.tsinghua.edu.cn

# Install PyTorch with CUDA 11.7 support
RUN pip3 install --no-cache-dir \
    torch==2.0.1+cu117 \
    torchvision==0.15.2+cu117 \
    torchaudio==2.0.2+cu117 \
    --index-url https://download.pytorch.org/whl/cu117

# Install Ultralytics YOLO
RUN pip3 install --no-cache-dir ultralytics>=8.0.0

# Install other dependencies
RUN pip3 install --no-cache-dir \
    numpy<2.0 \
    opencv-python-headless==4.9.0.80 \
    pillow==11.3.0 \
    matplotlib==3.10.6 \
    pyyaml>=6.0 \
    tqdm \
    pandas \
    seaborn

# Install ONNX runtime for validation
RUN pip3 install --no-cache-dir onnxruntime-gpu==1.18.1

# Copy project files
COPY requirements.txt requirements-dev.txt ./
COPY apps/ /workspace/apps/
COPY tools/ /workspace/tools/
COPY scripts/ /workspace/scripts/
COPY config/ /workspace/config/

# Set Python path
ENV PYTHONPATH=/workspace

# Verify GPU availability
RUN python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); \
    print(f'CUDA available: {torch.cuda.is_available()}'); \
    print(f'CUDA version: {torch.version.cuda}'); \
    print(f'GPU count: {torch.cuda.device_count()}'); \
    print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# Create artifacts directory
RUN mkdir -p /workspace/artifacts/models

# Expose Jupyter port (optional for monitoring)
EXPOSE 8888

# Default command: show help
CMD ["bash", "-c", "echo '=== GPU Training Container Ready ===' && \
    echo 'GPU Info:' && nvidia-smi && \
    echo '' && \
    echo 'Quick Start:' && \
    echo '  1. Download CityPersons dataset (manual registration required)' && \
    echo '  2. bash scripts/datasets/download_citypersons.sh' && \
    echo '  3. python scripts/datasets/prepare_citypersons.py' && \
    echo '  4. bash scripts/train/train_citypersons.sh' && \
    echo '' && \
    echo 'For interactive mode: docker run -it --gpus all <image> bash' && \
    exec bash"]
