#!/usr/bin/env python3
"""
YOLOæ•°æ®é›†å¥åº·æ£€æŸ¥è„šæœ¬
ä¸“é—¨é’ˆå¯¹"é«˜å¬å›ä½ç²¾åº¦"é—®é¢˜çš„æ•°æ®è´¨é‡è¯Šæ–­

ç”¨æ³•:
    python tools/data_health_check.py --data /path/to/data.yaml
    python tools/data_health_check.py --data /home/minsea01/datasets/industrial_15_classes_ready/data.yaml

è¾“å‡º:
    1. æ•°æ®è´¨é‡æŠ¥å‘Š (data_health_report.txt)
    2. ç±»åˆ«åˆ†å¸ƒå¯è§†åŒ– (class_distribution.png) 
    3. æ ·æœ¬å¯è§†åŒ– (sample_visualization.png)
    4. é—®é¢˜æ–‡ä»¶åˆ—è¡¨ (problem_files.txt)
"""

import os
import sys
import yaml
import glob
import argparse
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2
import numpy as np
from collections import Counter, defaultdict
import json

class DataHealthChecker:
    def __init__(self, data_yaml_path):
        self.data_yaml_path = Path(data_yaml_path)
        self.load_config()
        self.issues = []
        self.stats = {}
        
    def load_config(self):
        """åŠ è½½æ•°æ®é›†é…ç½®"""
        with open(self.data_yaml_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        self.dataset_path = Path(self.config['path'])
        self.num_classes = self.config['nc']
        self.class_names = self.config.get('names', [f'class_{i}' for i in range(self.num_classes)])
        
        print(f"ğŸ“Š æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
        print(f"ğŸ“Š ç±»åˆ«æ•°é‡: {self.num_classes}")
        print(f"ğŸ“Š ç±»åˆ«åç§°: {self.class_names}")
        
    def check_empty_labels(self, split='train'):
        """æ£€æŸ¥ç©ºæ ‡ç­¾æ–‡ä»¶"""
        print(f"\nğŸ” æ£€æŸ¥ {split} é›†ç©ºæ ‡ç­¾æ–‡ä»¶...")
        
        label_dir = self.dataset_path / split.replace('/images', '/labels')
        if not label_dir.exists():
            label_dir = self.dataset_path / f'{split}/labels'
            
        empty_files = []
        if label_dir.exists():
            for label_file in label_dir.glob('*.txt'):
                if label_file.stat().st_size == 0:
                    empty_files.append(str(label_file))
                    
        print(f"âŒ å‘ç° {len(empty_files)} ä¸ªç©ºæ ‡ç­¾æ–‡ä»¶")
        if empty_files:
            print("   ç¤ºä¾‹:", empty_files[:5])
            self.issues.append(f"{split} é›†æœ‰ {len(empty_files)} ä¸ªç©ºæ ‡ç­¾æ–‡ä»¶")
            
        return empty_files
    
    def check_missing_pairs(self, split='train'):
        """æ£€æŸ¥å›¾åƒå’Œæ ‡ç­¾é…å¯¹é—®é¢˜"""
        print(f"\nğŸ” æ£€æŸ¥ {split} é›†å›¾åƒ-æ ‡ç­¾é…å¯¹...")
        
        # è·å–å›¾åƒå’Œæ ‡ç­¾ç›®å½•
        img_dir = self.dataset_path / self.config[split]
        label_dir = self.dataset_path / self.config[split].replace('/images', '/labels')
        
        if not label_dir.exists():
            label_dir = self.dataset_path / f'{split}/labels'
            
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        img_files = set()
        label_files = set()
        
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            for img_file in img_dir.glob(ext):
                img_files.add(img_file.stem)
                
        for label_file in label_dir.glob('*.txt'):
            label_files.add(label_file.stem)
            
        # æ‰¾å‡ºä¸åŒ¹é…çš„æ–‡ä»¶
        missing_labels = img_files - label_files
        missing_images = label_files - img_files
        
        print(f"ğŸ“· å›¾åƒæ–‡ä»¶: {len(img_files)}")
        print(f"ğŸ·ï¸  æ ‡ç­¾æ–‡ä»¶: {len(label_files)}")
        print(f"âŒ ç¼ºå°‘æ ‡ç­¾: {len(missing_labels)}")
        print(f"âŒ ç¼ºå°‘å›¾åƒ: {len(missing_images)}")
        
        if missing_labels:
            print("   ç¼ºå°‘æ ‡ç­¾çš„å›¾åƒç¤ºä¾‹:", list(missing_labels)[:5])
            self.issues.append(f"{split} é›†æœ‰ {len(missing_labels)} ä¸ªå›¾åƒç¼ºå°‘æ ‡ç­¾")
            
        if missing_images:
            print("   ç¼ºå°‘å›¾åƒçš„æ ‡ç­¾ç¤ºä¾‹:", list(missing_images)[:5])
            self.issues.append(f"{split} é›†æœ‰ {len(missing_images)} ä¸ªæ ‡ç­¾ç¼ºå°‘å›¾åƒ")
            
        return missing_labels, missing_images
    
    def analyze_class_distribution(self, split='train'):
        """åˆ†æç±»åˆ«åˆ†å¸ƒ"""
        print(f"\nğŸ” åˆ†æ {split} é›†ç±»åˆ«åˆ†å¸ƒ...")
        
        label_dir = self.dataset_path / self.config[split].replace('/images', '/labels')
        if not label_dir.exists():
            label_dir = self.dataset_path / f'{split}/labels'
            
        class_counts = Counter()
        invalid_classes = []
        total_instances = 0
        
        for label_file in label_dir.glob('*.txt'):
            if label_file.stat().st_size == 0:
                continue
                
            with open(label_file, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        try:
                            class_id = int(parts[0])
                            if 0 <= class_id < self.num_classes:
                                class_counts[class_id] += 1
                                total_instances += 1
                            else:
                                invalid_classes.append((str(label_file), line_num, class_id))
                        except ValueError:
                            invalid_classes.append((str(label_file), line_num, parts[0]))
                            
        print(f"ğŸ“Š æ€»å®ä¾‹æ•°: {total_instances}")
        print(f"âŒ æ— æ•ˆç±»åˆ«: {len(invalid_classes)}")
        
        if invalid_classes:
            print("   æ— æ•ˆç±»åˆ«ç¤ºä¾‹:", invalid_classes[:5])
            self.issues.append(f"{split} é›†æœ‰ {len(invalid_classes)} ä¸ªæ— æ•ˆç±»åˆ«")
            
        # åˆ†æç±»åˆ«ä¸å‡è¡¡
        if class_counts:
            max_count = max(class_counts.values())
            min_count = min(class_counts.values())
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
            
            print(f"ğŸ“Š ç±»åˆ«ä¸å‡è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}")
            if imbalance_ratio > 10:
                self.issues.append(f"{split} é›†ç±»åˆ«ä¸¥é‡ä¸å‡è¡¡ (æ¯”ä¾‹: {imbalance_ratio:.2f})")
                
        self.stats[f'{split}_class_distribution'] = dict(class_counts)
        return class_counts, invalid_classes
    
    def check_annotation_quality(self, split='train', sample_count=50):
        """æ£€æŸ¥æ ‡æ³¨è´¨é‡ï¼ˆè¾¹ç•Œæ¡†åˆç†æ€§ï¼‰"""
        print(f"\nğŸ” æ£€æŸ¥ {split} é›†æ ‡æ³¨è´¨é‡...")
        
        img_dir = self.dataset_path / self.config[split]
        label_dir = self.dataset_path / self.config[split].replace('/images', '/labels')
        if not label_dir.exists():
            label_dir = self.dataset_path / f'{split}/labels'
            
        problematic_annotations = []
        very_small_boxes = []
        out_of_bounds = []
        
        # éšæœºé‡‡æ ·æ£€æŸ¥
        label_files = list(label_dir.glob('*.txt'))[:sample_count]
        
        for label_file in label_files:
            if label_file.stat().st_size == 0:
                continue
                
            # æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶
            img_file = None
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                potential_img = img_dir / (label_file.stem + ext)
                if potential_img.exists():
                    img_file = potential_img
                    break
                    
            if not img_file:
                continue
                
            # è¯»å–å›¾åƒå°ºå¯¸
            img = cv2.imread(str(img_file))
            if img is None:
                continue
            h, w = img.shape[:2]
            
            with open(label_file, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        try:
                            class_id = int(parts[0])
                            x_center, y_center, width, height = map(float, parts[1:5])
                            
                            # æ£€æŸ¥è¾¹ç•Œ
                            if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 
                                   0 < width <= 1 and 0 < height <= 1):
                                out_of_bounds.append((str(label_file), line_num))
                                
                            # æ£€æŸ¥æ˜¯å¦è¿‡å°
                            pixel_width = width * w
                            pixel_height = height * h
                            if pixel_width < 8 or pixel_height < 8:
                                very_small_boxes.append((str(label_file), line_num, pixel_width, pixel_height))
                                
                        except ValueError:
                            problematic_annotations.append((str(label_file), line_num))
                            
        print(f"âŒ é—®é¢˜æ ‡æ³¨: {len(problematic_annotations)}")
        print(f"âŒ è¶Šç•Œæ ‡æ³¨: {len(out_of_bounds)}")
        print(f"âš ï¸  æå°ç›®æ ‡: {len(very_small_boxes)}")
        
        if very_small_boxes:
            print("   æå°ç›®æ ‡ç¤ºä¾‹:", very_small_boxes[:5])
            
        if len(very_small_boxes) > sample_count * 0.1:
            self.issues.append(f"{split} é›†æœ‰å¤§é‡æå°ç›®æ ‡ ({len(very_small_boxes)} ä¸ª)")
            
        return problematic_annotations, out_of_bounds, very_small_boxes
    
    def visualize_samples(self, split='train', num_samples=8, output_path='sample_visualization.png'):
        """å¯è§†åŒ–æ ·æœ¬å’Œæ ‡æ³¨"""
        print(f"\nğŸ–¼ï¸ ç”Ÿæˆ {split} é›†å¯è§†åŒ–æ ·æœ¬...")
        
        img_dir = self.dataset_path / self.config[split]
        label_dir = self.dataset_path / self.config[split].replace('/images', '/labels')
        if not label_dir.exists():
            label_dir = self.dataset_path / f'{split}/labels'
            
        # éšæœºé€‰æ‹©æœ‰æ ‡æ³¨çš„å›¾åƒ
        valid_samples = []
        for label_file in label_dir.glob('*.txt'):
            if label_file.stat().st_size > 0:
                for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                    img_file = img_dir / (label_file.stem + ext)
                    if img_file.exists():
                        valid_samples.append((img_file, label_file))
                        break
                        
        if len(valid_samples) < num_samples:
            num_samples = len(valid_samples)
            
        samples = np.random.choice(len(valid_samples), num_samples, replace=False)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        axes = axes.ravel()
        
        colors = plt.cm.Set3(np.linspace(0, 1, self.num_classes))
        
        for i, idx in enumerate(samples):
            if i >= num_samples:
                break
                
            img_file, label_file = valid_samples[idx]
            
            # è¯»å–å›¾åƒ
            img = cv2.imread(str(img_file))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            h, w = img.shape[:2]
            
            axes[i].imshow(img)
            axes[i].set_title(f"{img_file.name}")
            axes[i].axis('off')
            
            # è¯»å–æ ‡æ³¨
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        try:
                            class_id = int(parts[0])
                            x_center, y_center, width, height = map(float, parts[1:5])
                            
                            # è½¬æ¢ä¸ºåƒç´ åæ ‡
                            x = (x_center - width/2) * w
                            y = (y_center - height/2) * h
                            w_box = width * w
                            h_box = height * h
                            
                            # ç»˜åˆ¶è¾¹ç•Œæ¡†
                            rect = patches.Rectangle((x, y), w_box, h_box, 
                                                   linewidth=2, edgecolor=colors[class_id], 
                                                   facecolor='none')
                            axes[i].add_patch(rect)
                            
                            # æ·»åŠ ç±»åˆ«æ ‡ç­¾
                            axes[i].text(x, y-5, self.class_names[class_id], 
                                       color=colors[class_id], fontsize=8, 
                                       bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.7))
                        except (ValueError, IndexError):
                            continue
                            
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“¸ æ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜: {output_path}")
    
    def plot_class_distribution(self, output_path='class_distribution.png'):
        """ç»˜åˆ¶ç±»åˆ«åˆ†å¸ƒå›¾"""
        train_dist = self.stats.get('train_class_distribution', {})
        val_dist = self.stats.get('val_class_distribution', {})
        
        if not train_dist:
            print("âš ï¸ æ²¡æœ‰è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒæ•°æ®")
            return
            
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # è®­ç»ƒé›†åˆ†å¸ƒ
        classes = list(range(self.num_classes))
        train_counts = [train_dist.get(i, 0) for i in classes]
        
        ax1.bar(classes, train_counts, color='skyblue', alpha=0.8)
        ax1.set_title('è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ')
        ax1.set_xlabel('ç±»åˆ«ID')
        ax1.set_ylabel('å®ä¾‹æ•°é‡')
        ax1.set_xticks(classes)
        ax1.set_xticklabels([self.class_names[i] for i in classes], rotation=45, ha='right')
        
        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for i, count in enumerate(train_counts):
            if count > 0:
                ax1.text(i, count + max(train_counts) * 0.01, str(count), 
                        ha='center', va='bottom', fontsize=8)
        
        # éªŒè¯é›†åˆ†å¸ƒï¼ˆå¦‚æœæœ‰ï¼‰
        if val_dist:
            val_counts = [val_dist.get(i, 0) for i in classes]
            ax2.bar(classes, val_counts, color='lightcoral', alpha=0.8)
            ax2.set_title('éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒ')
            ax2.set_xlabel('ç±»åˆ«ID')
            ax2.set_ylabel('å®ä¾‹æ•°é‡')
            ax2.set_xticks(classes)
            ax2.set_xticklabels([self.class_names[i] for i in classes], rotation=45, ha='right')
            
            for i, count in enumerate(val_counts):
                if count > 0:
                    ax2.text(i, count + max(val_counts) * 0.01, str(count), 
                            ha='center', va='bottom', fontsize=8)
        else:
            ax2.text(0.5, 0.5, 'æ— éªŒè¯é›†æ•°æ®', ha='center', va='center', 
                    transform=ax2.transAxes, fontsize=14)
            ax2.set_title('éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
    
    def generate_report(self, output_path='data_health_report.txt'):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print(f"\nğŸ“ ç”Ÿæˆæ•°æ®å¥åº·æŠ¥å‘Š...")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("YOLOæ•°æ®é›†å¥åº·æ£€æŸ¥æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"æ•°æ®é›†è·¯å¾„: {self.dataset_path}\n")
            f.write(f"ç±»åˆ«æ•°é‡: {self.num_classes}\n")
            f.write(f"ç±»åˆ«åç§°: {', '.join(self.class_names)}\n\n")
            
            f.write("ğŸ” å‘ç°çš„é—®é¢˜:\n")
            f.write("-" * 40 + "\n")
            if self.issues:
                for i, issue in enumerate(self.issues, 1):
                    f.write(f"{i}. {issue}\n")
            else:
                f.write("âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜\n")
            f.write("\n")
            
            f.write("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write("-" * 40 + "\n")
            for key, value in self.stats.items():
                if 'class_distribution' in key:
                    split = key.replace('_class_distribution', '')
                    total = sum(value.values())
                    f.write(f"{split} é›†æ€»å®ä¾‹æ•°: {total}\n")
                    
                    # æ‰¾å‡ºæœ€å¤šå’Œæœ€å°‘çš„ç±»åˆ«
                    if value:
                        max_class = max(value, key=value.get)
                        min_class = min(value, key=value.get)
                        f.write(f"  æœ€å¤šç±»åˆ«: {self.class_names[max_class]} ({value[max_class]} ä¸ª)\n")
                        f.write(f"  æœ€å°‘ç±»åˆ«: {self.class_names[min_class]} ({value[min_class]} ä¸ª)\n")
                        f.write(f"  ä¸å‡è¡¡æ¯”ä¾‹: {value[max_class] / value[min_class]:.2f}\n")
            f.write("\n")
            
            f.write("ğŸ’¡ å»ºè®®æªæ–½:\n")
            f.write("-" * 40 + "\n")
            
            # åŸºäºå‘ç°çš„é—®é¢˜ç»™å‡ºå»ºè®®
            if any('ç©ºæ ‡ç­¾' in issue for issue in self.issues):
                f.write("â€¢ åˆ é™¤æˆ–é‡æ–°æ ‡æ³¨ç©ºæ ‡ç­¾æ–‡ä»¶\n")
            if any('ç¼ºå°‘æ ‡ç­¾' in issue for issue in self.issues):
                f.write("â€¢ ä¸ºç¼ºå°‘æ ‡ç­¾çš„å›¾åƒè¡¥å……æ ‡æ³¨\n")
            if any('æ— æ•ˆç±»åˆ«' in issue for issue in self.issues):
                f.write("â€¢ æ£€æŸ¥å¹¶ä¿®æ­£æ— æ•ˆçš„ç±»åˆ«ID\n")
            if any('ä¸å‡è¡¡' in issue for issue in self.issues):
                f.write("â€¢ è€ƒè™‘è¿‡é‡‡æ ·å°‘æ•°ç±»æˆ–ä½¿ç”¨focal loss\n")
            if any('æå°ç›®æ ‡' in issue for issue in self.issues):
                f.write("â€¢ æé«˜è¾“å…¥åˆ†è¾¨ç‡ (imgsz=960 æˆ– 1280)\n")
                f.write("â€¢ å¯ç”¨å°ç›®æ ‡å‹å¥½çš„æ•°æ®å¢å¼º (mosaic, copy_paste)\n")
                
            f.write("\nå»ºè®®çš„è®­ç»ƒå‚æ•°è°ƒæ•´:\n")
            f.write("â€¢ æé«˜åˆ†è¾¨ç‡: imgsz=960\n")
            f.write("â€¢ å¢åŠ epochs: 150-200\n") 
            f.write("â€¢ ä½¿ç”¨focal loss: fl_gamma=1.5\n")
            f.write("â€¢ å¯ç”¨å¤šå°ºåº¦è®­ç»ƒ: multi_scale=True\n")
            f.write("â€¢ è°ƒæ•´NMSé˜ˆå€¼: iou=0.5-0.6\n")
            f.write("â€¢ éƒ¨ç½²æ—¶ä½¿ç”¨æ›´é«˜ç½®ä¿¡åº¦: conf=0.35-0.5\n")
            
        print(f"ğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    
    def run_full_check(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®å¥åº·æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹YOLOæ•°æ®é›†å¥åº·æ£€æŸ¥...")
        print("=" * 60)
        
        # æ£€æŸ¥å„ä¸ªåˆ†å‰²
        for split in ['train', 'val']:
            if split in self.config:
                print(f"\nğŸ“‚ æ£€æŸ¥ {split} é›†...")
                self.check_empty_labels(split)
                self.check_missing_pairs(split)
                self.analyze_class_distribution(split)
                self.check_annotation_quality(split)
        
        # ç”Ÿæˆå¯è§†åŒ–
        if 'train' in self.config:
            self.visualize_samples('train')
        self.plot_class_distribution()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        print("\nâœ… æ•°æ®å¥åº·æ£€æŸ¥å®Œæˆï¼")
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print("  - data_health_report.txt (ç»¼åˆæŠ¥å‘Š)")
        print("  - class_distribution.png (ç±»åˆ«åˆ†å¸ƒå›¾)")
        print("  - sample_visualization.png (æ ·æœ¬å¯è§†åŒ–)")
        
        # æ€»ç»“å…³é”®é—®é¢˜
        if self.issues:
            print(f"\nâš ï¸ å‘ç° {len(self.issues)} ä¸ªæ½œåœ¨é—®é¢˜ï¼Œè¯¦è§æŠ¥å‘Šã€‚")
            print("ğŸ¯ å…³é”®å»ºè®®: å…ˆä¿®å¤æ ‡ç­¾è´¨é‡é—®é¢˜ï¼Œå†è°ƒæ•´è®­ç»ƒå‚æ•°ã€‚")
        else:
            print("\nğŸ‰ æ•°æ®è´¨é‡è‰¯å¥½ï¼å¯ä»¥ä¸“æ³¨äºæ¨¡å‹è°ƒä¼˜ã€‚")

def main():
    parser = argparse.ArgumentParser(description='YOLOæ•°æ®é›†å¥åº·æ£€æŸ¥')
    parser.add_argument('--data', required=True, help='æ•°æ®é›†YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default='.', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ‡æ¢åˆ°è¾“å‡ºç›®å½•
    os.chdir(args.output_dir)
    
    # è¿è¡Œæ£€æŸ¥
    checker = DataHealthChecker(args.data)
    checker.run_full_check()

if __name__ == '__main__':
    main()
