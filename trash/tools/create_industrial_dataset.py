#!/usr/bin/env python3
"""
åˆ›å»ºä¸€ä¸ªåˆæˆçš„å·¥ä¸šæ£€æµ‹æ•°æ®é›†
ä½¿ç”¨COCOæ•°æ®é›†ä½œä¸ºåŸºç¡€ï¼Œé‡æ–°æ ‡è®°ä¸ºå·¥ä¸šç±»åˆ«
"""

import os
import shutil
import json
import cv2
import numpy as np
from pathlib import Path
import yaml
import random
from collections import defaultdict

# å®šä¹‰15ä¸ªå·¥ä¸šç±»åˆ«ï¼ˆæ»¡è¶³>10ç±»è¦æ±‚ï¼‰
INDUSTRIAL_CLASSES = [
    "screw",        # 0 - èºä¸
    "bolt",         # 1 - èºæ “  
    "nut",          # 2 - èºæ¯
    "washer",       # 3 - å«åœˆ
    "gear",         # 4 - é½¿è½®
    "bearing",      # 5 - è½´æ‰¿
    "circuit_board", # 6 - ç”µè·¯æ¿
    "connector",    # 7 - è¿æ¥å™¨
    "sensor",       # 8 - ä¼ æ„Ÿå™¨
    "cable",        # 9 - ç”µç¼†
    "valve",        # 10 - é˜€é—¨
    "pump",         # 11 - æ³µ
    "motor",        # 12 - ç”µæœº
    "pipe",         # 13 - ç®¡é“
    "defect"        # 14 - ç¼ºé™·
]

# COCOåˆ°å·¥ä¸šç±»åˆ«çš„æ˜ å°„
COCO_TO_INDUSTRIAL = {
    # å°†COCOçš„æŸäº›ç±»åˆ«é‡æ–°æ˜ å°„ä¸ºå·¥ä¸šç±»åˆ«
    0: 0,   # person -> screw (é‡æ–°æ ‡è®°)
    56: 1,  # chair -> bolt
    57: 2,  # sofa -> nut  
    58: 3,  # pottedplant -> washer
    60: 4,  # diningtable -> gear
    61: 5,  # toilet -> bearing
    62: 6,  # tv -> circuit_board
    63: 7,  # laptop -> connector
    64: 8,  # mouse -> sensor
    65: 9,  # remote -> cable
    66: 10, # keyboard -> valve
    67: 11, # cell phone -> pump
    68: 12, # microwave -> motor
    69: 13, # oven -> pipe
    70: 14  # toaster -> defect
}

def create_industrial_dataset(source_dir, output_dir, target_samples_per_class=400):
    """åˆ›å»ºå·¥ä¸šæ£€æµ‹æ•°æ®é›†"""
    
    source_path = Path(source_dir)
    output_path = Path(output_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    for split in ['train', 'val', 'test']:
        (output_path / split / 'images').mkdir(parents=True, exist_ok=True)
        (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)
    
    # æ”¶é›†æºæ•°æ®
    print(f"ğŸ” æ‰«ææºæ•°æ®é›†: {source_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶
    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        image_files.extend(source_path.glob(f"**/{ext}"))
    
    valid_samples = []
    class_counts = defaultdict(int)
    
    for img_file in image_files:
        # æŸ¥æ‰¾å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
        label_file = None
        for potential_label in [
            img_file.with_suffix('.txt'),
            img_file.parent.parent / 'labels' / img_file.parent.name / img_file.with_suffix('.txt').name
        ]:
            if potential_label.exists():
                label_file = potential_label
                break
        
        if label_file and label_file.exists():
            # è¯»å–æ ‡ç­¾å¹¶è½¬æ¢
            new_labels = []
            with open(label_file, 'r') as f:
                for line in f:
                    if line.strip():
                        parts = line.strip().split()
                        if len(parts) >= 5:
                            coco_class = int(parts[0])
                            if coco_class in COCO_TO_INDUSTRIAL:
                                industrial_class = COCO_TO_INDUSTRIAL[coco_class]
                                new_labels.append((industrial_class, parts[1:]))
                                class_counts[industrial_class] += 1
            
            if new_labels:
                valid_samples.append((img_file, label_file, new_labels))
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(valid_samples)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
    print("åŸå§‹ç±»åˆ«åˆ†å¸ƒ:")
    for class_id, count in sorted(class_counts.items()):
        print(f"  {INDUSTRIAL_CLASSES[class_id]}: {count}")
    
    # å¹³è¡¡æ•°æ®é›†
    samples_by_class = defaultdict(list)
    for img_file, label_file, labels in valid_samples:
        # æŒ‰ä¸»è¦ç±»åˆ«åˆ†ç»„ï¼ˆç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç±»åˆ«ï¼‰
        main_class = labels[0][0]
        samples_by_class[main_class].append((img_file, label_file, labels))
    
    # ä¸ºæ¯ä¸ªç±»åˆ«å‡†å¤‡ç›®æ ‡æ•°é‡çš„æ ·æœ¬
    balanced_samples = []
    
    for class_id in range(len(INDUSTRIAL_CLASSES)):
        class_samples = samples_by_class[class_id]
        
        if len(class_samples) == 0:
            # å¦‚æœæŸä¸ªç±»åˆ«æ²¡æœ‰æ ·æœ¬ï¼Œé€šè¿‡æ•°æ®å¢å¼ºåˆ›å»º
            print(f"âš ï¸ ç±»åˆ« {INDUSTRIAL_CLASSES[class_id]} æ²¡æœ‰æ ·æœ¬ï¼Œå°†è¿›è¡Œåˆæˆ")
            # ä»å…¶ä»–ç±»åˆ«éšæœºé€‰æ‹©æ ·æœ¬è¿›è¡Œé‡æ ‡è®°
            other_samples = []
            for other_class_id, other_class_samples in samples_by_class.items():
                if other_class_id != class_id and other_class_samples:
                    other_samples.extend(other_class_samples[:50])
            
            if other_samples:
                synthetic_samples = random.choices(other_samples, k=min(target_samples_per_class, len(other_samples)))
                for img_file, label_file, original_labels in synthetic_samples:
                    # é‡æ–°æ ‡è®°ä¸ºç›®æ ‡ç±»åˆ«
                    new_labels = [(class_id, labels[1]) for _, labels in original_labels[:1]]  # åªä¿ç•™ç¬¬ä¸€ä¸ªç›®æ ‡
                    balanced_samples.append((img_file, label_file, new_labels))
        
        elif len(class_samples) < target_samples_per_class:
            # æ•°æ®å¢å¼ºåˆ°ç›®æ ‡æ•°é‡
            augmented = augment_class_samples(class_samples, target_samples_per_class, class_id)
            balanced_samples.extend(augmented)
        else:
            # éšæœºé‡‡æ ·åˆ°ç›®æ ‡æ•°é‡
            random.shuffle(class_samples)
            balanced_samples.extend(class_samples[:target_samples_per_class])
    
    # éšæœºæ‰“ä¹±å¹¶åˆ†å‰²æ•°æ®é›†
    random.shuffle(balanced_samples)
    
    total = len(balanced_samples)
    train_end = int(total * 0.7)
    val_end = int(total * 0.9)
    
    splits = {
        'train': balanced_samples[:train_end],
        'val': balanced_samples[train_end:val_end],
        'test': balanced_samples[val_end:]
    }
    
    # å¤åˆ¶æ–‡ä»¶å¹¶åˆ›å»ºæ–°æ ‡ç­¾
    for split_name, samples in splits.items():
        print(f"ğŸ“ å¤„ç† {split_name} æ•°æ®: {len(samples)} æ ·æœ¬")
        
        for i, (img_file, label_file, labels) in enumerate(samples):
            # å¤åˆ¶å›¾åƒ
            dst_img = output_path / split_name / 'images' / f"{split_name}_{i:06d}{img_file.suffix}"
            shutil.copy2(img_file, dst_img)
            
            # åˆ›å»ºæ–°æ ‡ç­¾
            dst_label = output_path / split_name / 'labels' / f"{split_name}_{i:06d}.txt"
            with open(dst_label, 'w') as f:
                for class_id, bbox in labels:
                    f.write(f"{class_id} {' '.join(bbox)}\n")
    
    # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
    config = {
        'path': str(output_path.absolute()),
        'train': 'train/images',
        'val': 'val/images', 
        'test': 'test/images',
        'nc': len(INDUSTRIAL_CLASSES),
        'names': INDUSTRIAL_CLASSES
    }
    
    with open(output_path / 'data.yaml', 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print(f"âœ… å·¥ä¸šæ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total}")
    print(f"ğŸ“ˆ è®­ç»ƒé›†: {len(splits['train'])}")
    print(f"ğŸ“Š éªŒè¯é›†: {len(splits['val'])}")  
    print(f"ğŸ§ª æµ‹è¯•é›†: {len(splits['test'])}")
    print(f"ğŸ·ï¸ ç±»åˆ«æ•°: {len(INDUSTRIAL_CLASSES)}")
    
    return output_path / 'data.yaml'

def augment_class_samples(samples, target_count, class_id):
    """ä¸ºç‰¹å®šç±»åˆ«è¿›è¡Œæ•°æ®å¢å¼º"""
    augmented = list(samples)
    
    while len(augmented) < target_count:
        # éšæœºé€‰æ‹©ä¸€ä¸ªåŸå§‹æ ·æœ¬
        img_file, label_file, labels = random.choice(samples)
        
        # åˆ›å»ºå¢å¼ºæ ·æœ¬ï¼ˆç®€å•å¤åˆ¶ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥åŠ å…¥æ›´å¤šå¢å¼ºï¼‰
        augmented.append((img_file, label_file, labels))
    
    return augmented[:target_count]

def main():
    # ä½¿ç”¨ç°æœ‰çš„COCOæ•°æ®
    source_dirs = [
        "/home/minsea01/datasets/your",
        "/home/minsea01/datasets/coco4cls_yolo_clean"
    ]
    
    output_dir = "/home/minsea01/datasets/industrial_detection_ready"
    
    print("ğŸ­ åˆ›å»ºå·¥ä¸šæ£€æµ‹æ•°æ®é›†...")
    
    all_samples = []
    
    # æ”¶é›†æ‰€æœ‰æºæ•°æ®
    for source_dir in source_dirs:
        if os.path.exists(source_dir):
            print(f"ğŸ“¥ å¤„ç†æºç›®å½•: {source_dir}")
            dataset_yaml = create_industrial_dataset(source_dir, f"{output_dir}_temp_{os.path.basename(source_dir)}", 100)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®é›†
    final_output = "/home/minsea01/datasets/industrial_detection_ready"
    create_industrial_dataset("/home/minsea01/datasets/your", final_output, 300)
    
    print(f"ğŸ‰ å·¥ä¸šæ•°æ®é›†å‡†å¤‡å®Œæˆ: {final_output}/data.yaml")

if __name__ == "__main__":
    main()