#!/usr/bin/env python3
"""
å·¥ä¸šæ•°æ®é›†å¹³è¡¡å·¥å…·
å¹³è¡¡å„ç±»åˆ«æ ·æœ¬æ•°é‡ï¼Œç¡®ä¿è®­ç»ƒæ•ˆæœ
"""

import os
import shutil
import random
import yaml
from pathlib import Path
from collections import defaultdict, Counter
import cv2
import numpy as np

def analyze_dataset_distribution(dataset_dir):
    """åˆ†ææ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ"""
    label_files = list(Path(dataset_dir).glob("**/*.txt"))
    class_counts = Counter()
    
    for label_file in label_files:
        if label_file.name == "classes.txt":
            continue
            
        with open(label_file, 'r') as f:
            for line in f:
                if line.strip():
                    class_id = int(line.split()[0])
                    class_counts[class_id] += 1
    
    return class_counts

def balance_classes(source_dirs, output_dir, min_samples_per_class=300, 
                   train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
    """å¹³è¡¡ç±»åˆ«æ ·æœ¬æ•°é‡"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    for split in ['train', 'val', 'test']:
        (output_path / split / 'images').mkdir(parents=True, exist_ok=True)
        (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)
    
    # æ”¶é›†æ‰€æœ‰æ ·æœ¬
    samples_by_class = defaultdict(list)
    
    for source_dir in source_dirs:
        source_path = Path(source_dir)
        label_files = list(source_path.glob("**/*.txt"))
        
        for label_file in label_files:
            if label_file.name == "classes.txt":
                continue
                
            # æ‰¾åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶
            img_file = None
            for ext in ['.jpg', '.jpeg', '.png']:
                potential_img = label_file.with_suffix(ext)
                if potential_img.exists():
                    img_file = potential_img
                    break
            
            if img_file and img_file.exists():
                with open(label_file, 'r') as f:
                    for line in f:
                        if line.strip():
                            class_id = int(line.split()[0])
                            samples_by_class[class_id].append((img_file, label_file))
                            break  # åªè®°å½•ç¬¬ä¸€ä¸ªç±»åˆ«
    
    print("ğŸ“Š åŸå§‹ç±»åˆ«åˆ†å¸ƒ:")
    for class_id, samples in samples_by_class.items():
        print(f"  Class {class_id}: {len(samples)} samples")
    
    # å¹³è¡¡ç±»åˆ«
    balanced_samples = []
    for class_id, samples in samples_by_class.items():
        if len(samples) < min_samples_per_class:
            # æ•°æ®å¢å¼ºåˆ°æœ€å°æ ·æœ¬æ•°
            augmented_samples = augment_samples(samples, min_samples_per_class)
            balanced_samples.extend(augmented_samples)
        else:
            # éšæœºé‡‡æ ·åˆ°æœ€å°æ ·æœ¬æ•°
            random.shuffle(samples)
            balanced_samples.extend(samples[:min_samples_per_class])
    
    # æ‰“ä¹±å¹¶åˆ†å‰²æ•°æ®é›†
    random.shuffle(balanced_samples)
    total_samples = len(balanced_samples)
    
    train_split = int(total_samples * train_ratio)
    val_split = int(total_samples * (train_ratio + val_ratio))
    
    train_samples = balanced_samples[:train_split]
    val_samples = balanced_samples[train_split:val_split]
    test_samples = balanced_samples[val_split:]
    
    # å¤åˆ¶æ–‡ä»¶
    for split_name, samples in [('train', train_samples), 
                                ('val', val_samples), 
                                ('test', test_samples)]:
        print(f"ğŸ“ å¤„ç† {split_name} æ•°æ®é›†: {len(samples)} samples")
        
        for i, (img_file, label_file) in enumerate(samples):
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            dst_img = output_path / split_name / 'images' / f"{split_name}_{i:06d}{img_file.suffix}"
            shutil.copy2(img_file, dst_img)
            
            # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
            dst_label = output_path / split_name / 'labels' / f"{split_name}_{i:06d}.txt"
            shutil.copy2(label_file, dst_label)
    
    print("âœ… æ•°æ®é›†å¹³è¡¡å®Œæˆ!")
    print(f"ğŸ“ˆ è®­ç»ƒé›†: {len(train_samples)} samples")
    print(f"ğŸ“Š éªŒè¯é›†: {len(val_samples)} samples")
    print(f"ğŸ§ª æµ‹è¯•é›†: {len(test_samples)} samples")

def augment_samples(samples, target_count):
    """æ•°æ®å¢å¼ºåˆ°ç›®æ ‡æ•°é‡"""
    augmented = list(samples)
    
    while len(augmented) < target_count:
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå¢å¼º
        img_file, label_file = random.choice(samples)
        
        # ç®€å•çš„æ°´å¹³ç¿»è½¬å¢å¼º
        img = cv2.imread(str(img_file))
        if img is not None:
            # æ°´å¹³ç¿»è½¬
            flipped_img = cv2.flip(img, 1)
            
            # è°ƒæ•´æ ‡ç­¾ä¸­çš„xåæ ‡
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            adjusted_lines = []
            for line in lines:
                if line.strip():
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id, x, y, w, h = parts[:5]
                        x_new = 1.0 - float(x)  # æ°´å¹³ç¿»è½¬xåæ ‡
                        adjusted_lines.append(f"{class_id} {x_new:.6f} {y} {w} {h}\n")
            
            # åˆ›å»ºä¸´æ—¶å¢å¼ºæ–‡ä»¶
            aug_img_path = img_file.parent / f"aug_{len(augmented)}_{img_file.name}"
            aug_label_path = label_file.parent / f"aug_{len(augmented)}_{label_file.name}"
            
            cv2.imwrite(str(aug_img_path), flipped_img)
            with open(aug_label_path, 'w') as f:
                f.writelines(adjusted_lines)
            
            augmented.append((aug_img_path, aug_label_path))
    
    return augmented[:target_count]

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å¹³è¡¡å·¥ä¸šæ•°æ®é›†")
    parser.add_argument("--input-dirs", nargs="+", required=True,
                       help="è¾“å…¥æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output-dir", required=True,
                       help="è¾“å‡ºæ•°æ®é›†ç›®å½•")
    parser.add_argument("--min-samples-per-class", type=int, default=300,
                       help="æ¯ç±»æœ€å°æ ·æœ¬æ•°")
    parser.add_argument("--train-ratio", type=float, default=0.7,
                       help="è®­ç»ƒé›†æ¯”ä¾‹")
    parser.add_argument("--val-ratio", type=float, default=0.2,
                       help="éªŒè¯é›†æ¯”ä¾‹")
    parser.add_argument("--test-ratio", type=float, default=0.1,
                       help="æµ‹è¯•é›†æ¯”ä¾‹")
    
    args = parser.parse_args()
    
    # éªŒè¯æ¯”ä¾‹
    total_ratio = args.train_ratio + args.val_ratio + args.test_ratio
    if abs(total_ratio - 1.0) > 0.01:
        raise ValueError(f"æ•°æ®é›†åˆ†å‰²æ¯”ä¾‹æ€»å’Œåº”ä¸º1.0ï¼Œå½“å‰ä¸º{total_ratio}")
    
    print("ğŸ”§ å¼€å§‹å¹³è¡¡å·¥ä¸šæ•°æ®é›†...")
    balance_classes(
        source_dirs=args.input_dirs,
        output_dir=args.output_dir,
        min_samples_per_class=args.min_samples_per_class,
        train_ratio=args.train_ratio,
        val_ratio=args.val_ratio,
        test_ratio=args.test_ratio
    )
    print("ğŸ‰ æ•°æ®é›†å¹³è¡¡å®Œæˆï¼")