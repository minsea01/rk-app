#!/usr/bin/env python3
"""
YOLOæ•°æ®é›†è´¨é‡ä½“æ£€å·¥å…·
è¯Šæ–­"å¬å›çˆ†è¡¨ã€ç²¾åº¦åä½"é—®é¢˜çš„æ•°æ®æºå¤´
"""

import os
import glob
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
import yaml
import json
from datetime import datetime

def check_dataset_health(dataset_yaml):
    """å®Œæ•´çš„æ•°æ®é›†å¥åº·æ£€æŸ¥"""
    
    print("ğŸ¥ YOLOæ•°æ®é›†ä½“æ£€å¼€å§‹...")
    
    # è¯»å–æ•°æ®é›†é…ç½®
    with open(dataset_yaml, 'r') as f:
        config = yaml.safe_load(f)
    
    dataset_path = Path(config['path'])
    class_names = config['names']
    num_classes = config['nc']
    
    print(f"ğŸ“Š æ•°æ®é›†: {dataset_path}")
    print(f"ğŸ·ï¸ ç±»åˆ«æ•°: {num_classes}")
    print(f"ğŸ“ ç±»åˆ«: {class_names}")
    
    results = {}
    
    for split in ['train', 'val', 'test']:
        if split in config:
            print(f"\nğŸ” æ£€æŸ¥ {split} æ•°æ®é›†...")
            
            img_dir = dataset_path / config[split].replace('/images', '').replace('images/', '') / 'images'
            label_dir = dataset_path / config[split].replace('/images', '').replace('images/', '') / 'labels'
            
            split_results = check_split_data(img_dir, label_dir, class_names, split)
            results[split] = split_results
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_health_report(results, dataset_path)
    
    return results

def check_split_data(img_dir, label_dir, class_names, split_name):
    """æ£€æŸ¥å•ä¸ªæ•°æ®åˆ†å‰²"""
    
    if not img_dir.exists() or not label_dir.exists():
        print(f"âŒ {split_name} ç›®å½•ä¸å­˜åœ¨")
        return {}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    img_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        img_files.extend(glob.glob(str(img_dir / ext)))
    
    label_files = list(label_dir.glob('*.txt'))
    
    print(f"ğŸ“ å›¾åƒæ–‡ä»¶: {len(img_files)}")
    print(f"ğŸ“„ æ ‡ç­¾æ–‡ä»¶: {len(label_files)}")
    
    results = {
        'total_images': len(img_files),
        'total_labels': len(label_files),
        'issues': []
    }
    
    # 1. æ£€æŸ¥ç©ºæ ‡ç­¾æ–‡ä»¶
    empty_labels = []
    for label_file in label_files:
        if os.path.getsize(label_file) == 0:
            empty_labels.append(label_file)
    
    if empty_labels:
        results['issues'].append(f"ç©ºæ ‡ç­¾æ–‡ä»¶: {len(empty_labels)}ä¸ª")
        print(f"âš ï¸ å‘ç° {len(empty_labels)} ä¸ªç©ºæ ‡ç­¾æ–‡ä»¶")
        for empty_file in empty_labels[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"   - {empty_file}")
    
    # 2. æ£€æŸ¥å›¾åƒ-æ ‡ç­¾å¯¹åº”å…³ç³»
    img_stems = {Path(f).stem for f in img_files}
    label_stems = {f.stem for f in label_files}
    
    missing_labels = img_stems - label_stems
    missing_images = label_stems - img_stems
    
    if missing_labels:
        results['issues'].append(f"ç¼ºå¤±æ ‡ç­¾: {len(missing_labels)}ä¸ª")
        print(f"âŒ {len(missing_labels)} ä¸ªå›¾åƒç¼ºå¤±æ ‡ç­¾")
        for missing in list(missing_labels)[:5]:
            print(f"   - {missing}")
    
    if missing_images:
        results['issues'].append(f"ç¼ºå¤±å›¾åƒ: {len(missing_images)}ä¸ª")
        print(f"âŒ {len(missing_images)} ä¸ªæ ‡ç­¾ç¼ºå¤±å›¾åƒ")
    
    # 3. ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
    class_counts = Counter()
    bbox_counts = Counter()  # æ¯ä¸ªå›¾åƒçš„ç›®æ ‡æ•°é‡ç»Ÿè®¡
    small_objects = 0
    large_objects = 0
    
    valid_label_files = [f for f in label_files if os.path.getsize(f) > 0]
    
    for label_file in valid_label_files:
        bbox_count = 0
        try:
            with open(label_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            x, y, w, h = map(float, parts[1:5])
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨åˆæ³•èŒƒå›´å†…
                            if 0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1:
                                if class_id < len(class_names):
                                    class_counts[class_id] += 1
                                    bbox_count += 1
                                    
                                    # ç»Ÿè®¡ç›®æ ‡å¤§å°ï¼ˆå‡è®¾å›¾åƒ640x640ï¼‰
                                    area = w * h
                                    if area < 0.01:  # å°äº1%çš„å›¾åƒé¢ç§¯
                                        small_objects += 1
                                    elif area > 0.3:  # å¤§äº30%çš„å›¾åƒé¢ç§¯
                                        large_objects += 1
                                else:
                                    results['issues'].append(f"éæ³•ç±»åˆ«ID: {class_id}")
                            else:
                                results['issues'].append(f"è¾¹ç•Œæ¡†è¶Šç•Œ: {label_file}")
        
        except Exception as e:
            results['issues'].append(f"æ ‡ç­¾æ–‡ä»¶è§£æé”™è¯¯: {label_file} - {str(e)}")
        
        bbox_counts[bbox_count] += 1
    
    # ç»Ÿè®¡ç»“æœ
    results['class_distribution'] = dict(class_counts)
    results['bbox_per_image'] = dict(bbox_counts)
    results['small_objects'] = small_objects
    results['large_objects'] = large_objects
    
    # 4. ç±»åˆ«ä¸å¹³è¡¡æ£€æŸ¥
    if class_counts:
        max_count = max(class_counts.values())
        min_count = min(class_counts.values())
        imbalance_ratio = max_count / max(min_count, 1)
        
        if imbalance_ratio > 10:
            results['issues'].append(f"ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡: {imbalance_ratio:.1f}:1")
            print(f"âš ï¸ ç±»åˆ«ä¸å¹³è¡¡ä¸¥é‡: {imbalance_ratio:.1f}:1")
    
    print(f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
    for class_id, count in sorted(class_counts.items()):
        class_name = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
        print(f"   {class_name}: {count}")
    
    print(f"ğŸ¯ å°ç›®æ ‡: {small_objects}, å¤§ç›®æ ‡: {large_objects}")
    print(f"ğŸ“¦ å¹³å‡æ¯å›¾ç›®æ ‡æ•°: {sum(class_counts.values()) / max(len(valid_label_files), 1):.2f}")
    
    return results

def generate_health_report(results, dataset_path):
    """ç”Ÿæˆæ•°æ®é›†å¥åº·æŠ¥å‘Š"""
    
    report_path = dataset_path / 'dataset_health_report.json'
    
    # æ€»ç»“é—®é¢˜
    all_issues = []
    for split, split_data in results.items():
        if 'issues' in split_data:
            for issue in split_data['issues']:
                all_issues.append(f"{split}: {issue}")
    
    # åˆ†æå¬å›ç‡é«˜ã€ç²¾ç¡®åº¦ä½çš„å¯èƒ½åŸå› 
    diagnosis = []
    
    # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
    for split, split_data in results.items():
        if 'class_distribution' in split_data:
            class_dist = split_data['class_distribution']
            if len(class_dist) > 0:
                max_count = max(class_dist.values())
                min_count = min(class_dist.values())
                if max_count / max(min_count, 1) > 20:
                    diagnosis.append(f"â— {split}é›†ç±»åˆ«æåº¦ä¸å¹³è¡¡ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤ªå¤šå°ç›®æ ‡
                small_ratio = split_data.get('small_objects', 0) / max(sum(class_dist.values()), 1)
                if small_ratio > 0.5:
                    diagnosis.append(f"â— {split}é›†å°ç›®æ ‡è¿‡å¤š({small_ratio:.1%})ï¼Œå»ºè®®æé«˜åˆ†è¾¨ç‡")
    
    # æ£€æŸ¥æ ‡ç­¾è´¨é‡
    total_empty = sum(1 for split_data in results.values() 
                     for issue in split_data.get('issues', []) 
                     if 'ç©ºæ ‡ç­¾' in issue)
    
    if total_empty > 0:
        diagnosis.append(f"â— å‘ç°{total_empty}ä¸ªæ•°æ®åˆ†å‰²æœ‰ç©ºæ ‡ç­¾ï¼Œä¼šå¯¼è‡´FPå¢åŠ ")
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_issues': len(all_issues),
            'diagnosis': diagnosis
        },
        'detailed_results': results,
        'issues': all_issues,
        'recommendations': generate_recommendations(results)
    }
    
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nğŸ“‹ å¥åº·æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    # æ‰“å°è¯Šæ–­ç»“æœ
    if diagnosis:
        print("\nğŸ” é—®é¢˜è¯Šæ–­:")
        for d in diagnosis:
            print(f"   {d}")
    else:
        print("\nâœ… æ•°æ®é›†å¥åº·çŠ¶å†µè‰¯å¥½")

def generate_recommendations(results):
    """ç”Ÿæˆä¿®å¤å»ºè®®"""
    
    recommendations = []
    
    # åŸºäºå‘ç°çš„é—®é¢˜ç»™å‡ºå»ºè®®
    for split, split_data in results.items():
        issues = split_data.get('issues', [])
        
        for issue in issues:
            if 'ç©ºæ ‡ç­¾' in issue:
                recommendations.append("åˆ é™¤ç©ºæ ‡ç­¾æ–‡ä»¶åŠå¯¹åº”å›¾åƒ")
            elif 'ç±»åˆ«ä¸å¹³è¡¡' in issue:
                recommendations.append("å¯¹å°‘æ•°ç±»è¿›è¡Œæ•°æ®å¢å¼ºæˆ–é‡é‡‡æ ·")
            elif 'ç¼ºå¤±' in issue:
                recommendations.append("ä¿®å¤å›¾åƒ-æ ‡ç­¾å¯¹åº”å…³ç³»")
            elif 'è¾¹ç•Œæ¡†è¶Šç•Œ' in issue:
                recommendations.append("ä¿®æ­£æ ‡ç­¾æ–‡ä»¶ä¸­çš„åæ ‡é”™è¯¯")
    
    # é€šç”¨å»ºè®®
    recommendations.extend([
        "ä½¿ç”¨æ›´é«˜åˆ†è¾¨ç‡è®­ç»ƒ(imgsz=960)",
        "å¢åŠ focal lossæŠ‘åˆ¶æ˜“æ ·æœ¬(fl_gamma=1.5)",
        "å¼€å¯å¼ºæ•°æ®å¢å¼º(mosaic=1.0, mixup=0.1)",
        "è°ƒæ•´confé˜ˆå€¼è¿›è¡Œæ¨ç†(0.35-0.5)"
    ])
    
    return list(set(recommendations))  # å»é‡

def visualize_sample_annotations(dataset_yaml, num_samples=5):
    """å¯è§†åŒ–æ ·æœ¬æ ‡æ³¨è´¨é‡"""
    
    with open(dataset_yaml, 'r') as f:
        config = yaml.safe_load(f)
    
    dataset_path = Path(config['path'])
    
    # ä»è®­ç»ƒé›†é€‰æ‹©æ ·æœ¬
    img_dir = dataset_path / 'train' / 'images'
    label_dir = dataset_path / 'train' / 'labels'
    
    img_files = list(img_dir.glob('*.jpg'))[:num_samples]
    
    fig, axes = plt.subplots(1, len(img_files), figsize=(4*len(img_files), 4))
    if len(img_files) == 1:
        axes = [axes]
    
    for i, img_file in enumerate(img_files):
        # è¯»å–å›¾åƒ
        img = cv2.imread(str(img_file))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w = img.shape[:2]
        
        # è¯»å–æ ‡ç­¾
        label_file = label_dir / f"{img_file.stem}.txt"
        
        if label_file.exists():
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id, x_center, y_center, width, height = map(float, parts[:5])
                        
                        # è½¬æ¢ä¸ºåƒç´ åæ ‡
                        x1 = int((x_center - width/2) * w)
                        y1 = int((y_center - height/2) * h)
                        x2 = int((x_center + width/2) * w)
                        y2 = int((y_center + height/2) * h)
                        
                        # ç”»è¾¹ç•Œæ¡†
                        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(img, f"C{int(class_id)}", (x1, y1-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        axes[i].imshow(img)
        axes[i].set_title(f"Sample {i+1}")
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.savefig(dataset_path / 'sample_annotations.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ“¸ æ ·æœ¬æ ‡æ³¨å¯è§†åŒ–å·²ä¿å­˜: {dataset_path}/sample_annotations.png")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='YOLOæ•°æ®é›†å¥åº·æ£€æŸ¥')
    parser.add_argument('--data', type=str, required=True, help='æ•°æ®é›†YAMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆæ ‡æ³¨å¯è§†åŒ–')
    parser.add_argument('--samples', type=int, default=5, help='å¯è§†åŒ–æ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œå¥åº·æ£€æŸ¥
    results = check_dataset_health(args.data)
    
    # å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    if args.visualize:
        try:
            visualize_sample_annotations(args.data, args.samples)
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")
    
    print("\nğŸ‰ æ•°æ®é›†ä½“æ£€å®Œæˆï¼")

if __name__ == "__main__":
    main()