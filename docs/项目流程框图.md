# RK3588行人检测项目 - 流程框图集

本文档包含RK3588行人检测项目的10个关键流程框图，涵盖从模型训练到板端部署的完整工作流。

---

## 1. 模型转换完整流程 (PyTorch → ONNX → RKNN)

```mermaid
graph TD
    A[YOLOv8/v11 PyTorch模型<br/>yolo11n.pt] --> B[导出到ONNX]
    B --> |export_yolov8_to_onnx.py| C[ONNX模型<br/>yolo11n.onnx]
    C --> D[ONNX验证]
    D --> |onnxruntime推理| E{验证通过?}
    E --> |否| F[修复模型]
    F --> B
    E --> |是| G[准备校准数据集]
    G --> |300张COCO person图像| H[生成绝对路径列表<br/>calib.txt]
    H --> I[ONNX转RKNN]
    I --> |convert_onnx_to_rknn.py<br/>--do-quant| J[RKNN模型<br/>yolo11n.rknn]
    J --> K[PC模拟器验证]
    K --> |run_rknn_sim.py| L{精度对比<br/>误差<5%?}
    L --> |否| M[调整量化参数]
    M --> I
    L --> |是| N[转换完成<br/>可部署]

    style A fill:#e1f5ff
    style C fill:#fff4e6
    style J fill:#e8f5e9
    style N fill:#f3e5f5
```

---

## 2. PC仿真验证流程 (Boardless Workflow)

```mermaid
graph LR
    A[ONNX模型] --> B[RKNN-Toolkit2<br/>PC模拟器]
    B --> C[加载ONNX]
    C --> |rk.load_onnx| D[构建模型]
    D --> |rk.build<br/>config target_platform| E[准备输入数据]
    E --> F[图像预处理]
    F --> |NHWC格式<br/>1,640,640,3| G[执行推理]
    G --> |rk.inference<br/>data_format='nhwc'| H[获取输出]
    H --> I[后处理]
    I --> |NMS + 解码| J[检测结果]
    J --> K[ONNX对比]
    K --> |compare_onnx_rknn.py| L{精度验证}
    L --> |通过| M[PC验证完成]
    L --> |失败| N[调试模型]
    N --> C

    style A fill:#e1f5ff
    style E fill:#fff4e6
    style J fill:#e8f5e9
    style M fill:#f3e5f5
```

---

## 3. 板端部署流程 (RK3588 Deployment)

```mermaid
graph TD
    A[RKNN模型<br/>yolo11n.rknn] --> B{部署模式选择}
    B --> |Python| C[Python推理脚本]
    B --> |C++| D[交叉编译]

    C --> E[rk3588_run.sh<br/>--runner python]
    D --> |CMake arm64 preset| F[ARM64二进制]
    F --> G[rk3588_run.sh<br/>自动检测CLI]

    E --> H[rknn-toolkit2-lite]
    G --> H
    H --> I[加载.rknn模型]
    I --> J[初始化NPU]
    J --> |3核NPU<br/>RK3588| K[读取输入]
    K --> L[预处理<br/>uint8 NHWC]
    L --> M[NPU推理]
    M --> |<40ms目标| N[后处理]
    N --> O[检测结果]
    O --> P[UDP网络传输]
    P --> Q[可视化/存储]

    R[SSH部署] --> |deploy_to_board.sh| S[推送到开发板]
    S --> T[远程执行]
    T --> H

    style A fill:#e1f5ff
    style F fill:#fff4e6
    style M fill:#e8f5e9
    style Q fill:#f3e5f5
```

---

## 4. MCP基准测试流程 (Benchmark Pipeline)

```mermaid
graph LR
    A[启动基准测试<br/>run_bench.sh] --> B[iperf3网络测试]
    B --> |iperf3_bench.sh| C[生成iperf3.json<br/>带宽/抖动/丢包]
    C --> D[ffprobe媒体探测]
    D --> |ffprobe_probe.sh| E[生成ffprobe.json<br/>1080p@30fps]
    E --> F[聚合结果]
    F --> |aggregate.py| G[bench_summary.json/csv]
    G --> H[生成报告]
    H --> I[bench_report.md]
    I --> J[HTTP POST验证]
    J --> |http_post.py| K[http_receiver.py]
    K --> L[http_ingest.log]
    L --> M[基准测试完成]

    N[失败处理] --> |优雅降级| O[生成error字段]
    O --> F

    style A fill:#e1f5ff
    style C fill:#fff4e6
    style E fill:#fff4e6
    style I fill:#e8f5e9
    style M fill:#f3e5f5
```

---

## 5. mAP评估流程 (Pedestrian Detection Evaluation)

```mermaid
graph TD
    A[准备评估数据] --> B[COCO person子集]
    B --> |prepare_coco_person.sh| C[标注文件<br/>person_val2017.json]
    C --> D[选择评估模式]

    D --> |快速评估| E[official_yolo_map.py]
    D --> |综合评估| F[pedestrian_map_evaluator.py]

    E --> G[加载YOLO模型]
    G --> |.pt/.onnx| H[批量推理]
    H --> I[计算mAP@0.5]
    I --> J[输出结果JSON]

    F --> K[加载ONNX模型]
    F --> L[加载RKNN模型]
    K --> M[ONNX推理]
    L --> N[RKNN推理]
    M --> O[对比分析]
    N --> O
    O --> P[精度对比报告]
    P --> Q[mAP差异分析]

    J --> R[结果汇总]
    Q --> R
    R --> S[评估完成<br/>当前: 61.57% mAP<br/>目标: ≥90% mAP]

    style A fill:#e1f5ff
    style C fill:#fff4e6
    style I fill:#e8f5e9
    style S fill:#f3e5f5
```

---

## 6. 数据预处理流程 (Multi-Runtime Preprocessing)

```mermaid
graph TD
    A[输入图像] --> B{运行时类型}

    B --> |ONNX Runtime| C[preprocess_onnx]
    C --> D[BGR → RGB]
    D --> E[Resize 640×640]
    E --> F[归一化 /255.0]
    F --> G[转换 NCHW<br/>1,3,640,640]
    G --> H[float32]
    H --> I[ONNX推理]

    B --> |RKNN PC模拟器| J[preprocess_rknn_sim]
    J --> K[BGR → RGB]
    K --> L[Resize 640×640]
    L --> M[保持uint8<br/>0-255]
    M --> N[转换 NHWC<br/>1,640,640,3]
    N --> O[RKNN PC推理]

    B --> |RK3588板端| P[preprocess_board]
    P --> Q[BGR → RGB]
    Q --> R[Resize 640×640]
    R --> S[保持uint8<br/>0-255]
    S --> T[转换 NHWC<br/>1,640,640,3]
    T --> U[NPU推理]

    style A fill:#e1f5ff
    style I fill:#e8f5e9
    style O fill:#e8f5e9
    style U fill:#e8f5e9
```

---

## 7. RKNN推理完整流程 (PC模拟器 vs 板端)

```mermaid
graph LR
    subgraph PC模拟器
    A1[ONNX模型] --> B1[rk.load_onnx]
    B1 --> C1[rk.build<br/>target='rk3588']
    C1 --> D1[NHWC输入<br/>uint8]
    D1 --> E1[rk.inference<br/>data_format='nhwc']
    E1 --> F1[获取输出]
    end

    subgraph RK3588板端
    A2[RKNN模型] --> B2[rknn_lite.load_rknn]
    B2 --> C2[init_runtime<br/>core_mask=7]
    C2 --> D2[NHWC输入<br/>uint8]
    D2 --> E2[inference]
    E2 --> F2[获取输出]
    end

    F1 --> G[后处理]
    F2 --> G
    G --> H[解码DFL head]
    H --> I[NMS过滤]
    I --> J[坐标转换]
    J --> K[检测框+置信度]

    style A1 fill:#e1f5ff
    style A2 fill:#fff4e6
    style G fill:#e8f5e9
    style K fill:#f3e5f5
```

---

## 8. 校准数据集准备流程 (Calibration Dataset)

```mermaid
graph TD
    A[COCO数据集] --> B[筛选person类别]
    B --> |category_id=1| C[pick_person_subset.py]
    C --> D[提取300张图像]
    D --> E[保存到calib_images/]
    E --> F[生成路径列表]
    F --> G{路径类型检查}
    G --> |相对路径| H[❌ 转换错误<br/>重复路径前缀]
    G --> |绝对路径| I[✅ 正确]
    H --> J[使用realpath转换]
    J --> K[find -exec realpath]
    K --> L[生成calib.txt]
    I --> L
    L --> M[验证路径]
    M --> N{文件存在?}
    N --> |否| O[修复路径]
    O --> M
    N --> |是| P[校准列表就绪]
    P --> Q[用于RKNN量化]

    style A fill:#e1f5ff
    style D fill:#fff4e6
    style P fill:#e8f5e9
    style Q fill:#f3e5f5
```

---

## 9. CityPersons微调流程 (Fine-tuning to ≥90% mAP)

```mermaid
graph TD
    A[下载CityPersons数据集] --> B[手动注册<br/>cityscapes-dataset.com]
    B --> C[下载标注文件]
    C --> D[运行prepare_citypersons.py]
    D --> E[转换为YOLO格式]
    E --> F[数据集划分]
    F --> G[训练集: 2,975张]
    F --> H[验证集: 500张]
    G --> I[配置训练参数]
    H --> I
    I --> J[设置超参数<br/>epochs=50<br/>batch=16<br/>imgsz=640]
    J --> K[启动训练]
    K --> |train_citypersons.sh| L[YOLO11n微调]
    L --> M[训练2-4小时<br/>RTX 3060]
    M --> N[保存最佳模型<br/>best.pt]
    N --> O[评估mAP]
    O --> |official_yolo_map.py| P{mAP ≥ 90%?}
    P --> |否| Q[调整超参数]
    Q --> K
    P --> |是| R[微调完成<br/>达标准]
    R --> S[导出ONNX]
    S --> T[转换RKNN]
    T --> U[部署到RK3588]

    style A fill:#e1f5ff
    style L fill:#fff4e6
    style R fill:#e8f5e9
    style U fill:#f3e5f5
```

---

## 10. 完整开发工作流 (End-to-End Development)

```mermaid
graph TD
    A[项目启动] --> B[模型选择<br/>YOLO11n]
    B --> C[基线训练]
    C --> |COCO预训练| D[导出ONNX<br/>export_yolov8_to_onnx.py]
    D --> E[ONNX验证<br/>onnxruntime GPU]
    E --> |8.6ms @ 416×416| F[准备校准数据<br/>300张person图像]
    F --> G[RKNN转换<br/>INT8量化]
    G --> H[PC模拟器验证<br/>run_rknn_sim.py]
    H --> I[精度对比<br/>compare_onnx_rknn.py]
    I --> J{误差 < 5%?}
    J --> |否| K[调整量化参数]
    K --> G
    J --> |是| L[mAP基线评估]
    L --> M[61.57% mAP@0.5]
    M --> N{需要优化?}
    N --> |是| O[CityPersons微调]
    O --> P[≥90% mAP目标]
    N --> |否| P
    P --> Q[交叉编译<br/>ARM64二进制]
    Q --> R[部署脚本准备<br/>rk3588_run.sh]
    R --> S{硬件可用?}
    S --> |是| T[SSH部署到板端]
    T --> U[板端性能测试]
    U --> V[NPU推理<br/>25-35 FPS]
    S --> |否| W[PC模拟验证完成]
    V --> X[双网口测试]
    W --> X
    X --> Y[MCP基准测试<br/>run_bench.sh]
    Y --> Z[生成测试报告]
    Z --> AA[毕业论文撰写<br/>7章+开题报告]
    AA --> AB[代码质量检查<br/>pytest + coverage]
    AB --> AC[项目交付]
    AC --> AD[答辩准备]

    style A fill:#e1f5ff
    style M fill:#fff4e6
    style V fill:#e8f5e9
    style AC fill:#f3e5f5
    style AD fill:#f3e5f5
```

---

## 流程图使用说明

### 查看方式

1. **GitHub/GitLab**: 自动渲染Mermaid图表
2. **VSCode**: 安装Markdown Preview Mermaid扩展
3. **在线工具**: 复制代码到 [mermaid.live](https://mermaid.live)
4. **导出**: 使用mermaid-cli转换为PNG/SVG

### 颜色标注说明

- **浅蓝色 (#e1f5ff)**: 起始节点/输入数据
- **浅橙色 (#fff4e6)**: 处理过程/转换操作
- **浅绿色 (#e8f5e9)**: 关键结果/中间输出
- **浅紫色 (#f3e5f5)**: 完成节点/最终交付

### 关键节点说明

#### 模型转换流程 (图1)
- **关键路径**: PyTorch → ONNX → RKNN
- **验证点**: ONNX精度验证、RKNN精度对比
- **输出**: 可部署的`.rknn`模型

#### PC仿真流程 (图2)
- **关键点**: NHWC格式、data_format参数
- **优势**: 无需硬件即可验证模型功能
- **限制**: 性能不代表真实NPU速度

#### 板端部署 (图3)
- **部署模式**: Python脚本 or C++二进制
- **关键工具**: rk3588_run.sh (一键启动)
- **性能目标**: <40ms推理延迟

#### MCP基准测试 (图4)
- **测试维度**: 网络带宽、媒体质量、HTTP传输
- **容错机制**: 优雅降级，生成error字段
- **输出**: 综合性能报告

#### mAP评估 (图5)
- **当前基线**: 61.57% mAP@0.5 (YOLO11n预训练)
- **目标**: ≥90% mAP@0.5 (CityPersons微调后)
- **工具**: 3种评估器（快速/综合/对比）

#### 数据预处理 (图6)
- **三种模式**: ONNX (NCHW float32) / RKNN PC (NHWC uint8) / Board (NHWC uint8)
- **关键差异**: 归一化、数据布局、数据类型
- **配置管理**: apps/config.py统一管理

#### RKNN推理 (图7)
- **PC模拟器**: 需load_onnx + build，不支持直接加载.rknn
- **板端**: 加载.rknn，初始化NPU，多核并行
- **后处理**: DFL解码 + NMS过滤

#### 校准数据集 (图8)
- **数据量**: 300张COCO person图像
- **路径陷阱**: 必须使用绝对路径，相对路径会导致重复前缀
- **验证**: 确保所有文件存在且可读

#### CityPersons微调 (图9)
- **数据集规模**: 2,975训练 + 500验证
- **训练时间**: 2-4小时 (RTX 3060)
- **目标**: 从61.57%提升到≥90% mAP
- **状态**: 准备就绪，可选执行

#### 完整工作流 (图10)
- **里程碑**: 模型训练 → 转换 → 验证 → 部署 → 测试 → 交付
- **当前进度**: 98%完成（硬件验证待完成）
- **核心价值**: 端到端可重复流程

---

## 技术规格总结

### 性能指标

| 阶段 | 平台 | 输入尺寸 | 延迟 | FPS |
|------|------|----------|------|-----|
| ONNX GPU | RTX 3060 | 416×416 | 8.6ms | 116 |
| ONNX GPU | RTX 3060 | 640×640 | 12.5ms | 80 |
| RKNN PC模拟器 | x86 CPU | 640×640 | 354ms | 2.8 |
| RKNN NPU (预计) | RK3588 | 416×416 | 25-35ms | 28-40 |
| RKNN NPU (预计) | RK3588 | 640×640 | 35-45ms | 22-28 |

### 模型规格

- **模型**: YOLO11n
- **大小**: 4.7MB (✅ <5MB要求)
- **量化**: INT8 (w8a8)
- **基线mAP**: 61.57% @ COCO person
- **目标mAP**: ≥90% @ CityPersons

### 硬件平台

- **芯片**: RK3588
- **NPU**: 6 TOPS (3核并行)
- **CPU**: 4×A76 + 4×A55
- **内存**: 16GB
- **功耗**: 10W典型

---

## 相关文档

- **项目指南**: `CLAUDE.md`
- **论文文档**: `docs/thesis_*.md` (7章)
- **部署指南**: `docs/deployment/`
- **技术指南**: `docs/docs/`
- **自动化**: `.claude/commands/` (5个斜杠命令)

---

**生成时间**: 2025-11-17
**项目状态**: Phase 1 完成 (98%)
**文档版本**: v1.0
