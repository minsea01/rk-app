# Docker GPU Training Guide
## ä½¿ç”¨Dockerè¿›è¡ŒYOLOæ¨¡å‹Fine-tuning

**ç›®æ ‡ï¼š** åœ¨GPUç¯å¢ƒä¸‹ä½¿ç”¨CityPersonsæ•°æ®é›†fine-tuning YOLO11nï¼Œè¾¾åˆ°â‰¥90% mAP@0.5

---

## ğŸ“‹ å‰ç½®è¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- NVIDIA GPU (æ¨èRTX 3060æˆ–æ›´é«˜)
- è‡³å°‘20GBç£ç›˜ç©ºé—´ï¼ˆ11GBæ•°æ®é›† + æ¨¡å‹ + ç¼“å­˜ï¼‰
- è‡³å°‘16GB RAM

### è½¯ä»¶è¦æ±‚
- Docker Engine >= 20.10
- NVIDIA Docker Runtime (nvidia-docker2)
- NVIDIA Driver >= 470.x (æ”¯æŒCUDA 11.7)

### éªŒè¯GPUå¯ç”¨æ€§
```bash
# æ£€æŸ¥Dockerç‰ˆæœ¬
docker --version

# æ£€æŸ¥NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:11.7.0-base-ubuntu22.04 nvidia-smi
```

å¦‚æœçœ‹åˆ°GPUä¿¡æ¯ï¼Œè¯´æ˜ç¯å¢ƒé…ç½®æ­£ç¡® âœ…

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1ï¼šä½¿ç”¨docker-composeï¼ˆæ¨èï¼‰

```bash
# 1. æ„å»ºè®­ç»ƒé•œåƒï¼ˆé¦–æ¬¡éœ€è¦5-10åˆ†é’Ÿï¼‰
docker-compose -f docker-compose.train.yml build train-gpu

# 2. å¯åŠ¨è®­ç»ƒå®¹å™¨ï¼ˆäº¤äº’å¼ï¼‰
docker-compose -f docker-compose.train.yml run --rm train-gpu bash

# 3. å®¹å™¨å†…æ“ä½œï¼ˆæ¥ä¸‹æ¥çš„æ­¥éª¤éƒ½åœ¨å®¹å™¨å†…æ‰§è¡Œï¼‰
```

### æ–¹æ³•2ï¼šä½¿ç”¨Dockerå‘½ä»¤

```bash
# 1. æ„å»ºé•œåƒ
docker build -f Dockerfile.train -t rk-app-train:latest .

# 2. è¿è¡Œå®¹å™¨
docker run --rm -it --gpus all \
  -v $(pwd)/datasets:/workspace/datasets \
  -v $(pwd)/artifacts:/workspace/artifacts \
  -v $(pwd)/runs:/workspace/runs \
  rk-app-train:latest bash

# 3. å®¹å™¨å†…æ“ä½œï¼ˆæ¥ä¸‹æ¥çš„æ­¥éª¤éƒ½åœ¨å®¹å™¨å†…æ‰§è¡Œï¼‰
```

---

## ğŸ“¦ Step 1: å‡†å¤‡CityPersonsæ•°æ®é›†

### 1.1 åœ¨å®¹å™¨å¤–ï¼ˆå®¿ä¸»æœºï¼‰ä¸‹è½½æ•°æ®é›†

**é‡è¦ï¼š** CityPersonsåŸºäºCityScapesï¼Œéœ€è¦æ‰‹åŠ¨æ³¨å†Œä¸‹è½½ã€‚

1. **æ³¨å†Œè´¦å·ï¼š** https://www.cityscapes-dataset.com/register/
2. **ç™»å½•å¹¶ä¸‹è½½ï¼š**
   - `leftImg8bit_trainvaltest.zip` (11GB) - å›¾åƒ
   - ä» https://github.com/cvgroup-njust/CityPersons ä¸‹è½½æ ‡æ³¨

3. **æ”¾ç½®æ–‡ä»¶åˆ°ï¼š**
   ```bash
   # åœ¨å®¿ä¸»æœºä¸Šï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
   mkdir -p datasets/citypersons/raw
   cd datasets/citypersons/raw
   # å°†ä¸‹è½½çš„zipæ–‡ä»¶æ”¾åˆ°è¿™é‡Œ
   ```

### 1.2 åœ¨å®¹å™¨å†…è§£å‹å’Œè½¬æ¢

```bash
# è¿›å…¥å®¹å™¨åæ‰§è¡Œ

# è§£å‹æ•°æ®é›†
bash scripts/datasets/download_citypersons.sh

# è½¬æ¢ä¸ºYOLOæ ¼å¼
python scripts/datasets/prepare_citypersons.py

# éªŒè¯æ•°æ®é›†
ls datasets/citypersons/yolo/train/images | wc -l  # åº”è¯¥æ˜¯ 2975
ls datasets/citypersons/yolo/val/images | wc -l    # åº”è¯¥æ˜¯ 500
```

**é¢„æœŸè¾“å‡ºï¼š**
```
datasets/citypersons/yolo/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/  (2975 .png files)
â”‚   â””â”€â”€ labels/  (2975 .txt files)
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/  (500 .png files)
â”‚   â””â”€â”€ labels/  (500 .txt files)
â””â”€â”€ citypersons.yaml
```

---

## ğŸ‹ï¸ Step 2: Fine-tuningè®­ç»ƒ

### 2.1 éªŒè¯GPUå¯ç”¨

```bash
# åœ¨å®¹å™¨å†…æ‰§è¡Œ
python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0)}')"

# é¢„æœŸè¾“å‡º:
# CUDA: True, GPU: NVIDIA GeForce RTX 3060
```

### 2.2 å¼€å§‹è®­ç»ƒ

```bash
# å•å‘½ä»¤å¯åŠ¨ï¼ˆå·²é¢„é…ç½®æ‰€æœ‰å‚æ•°ï¼‰
bash scripts/train/train_citypersons.sh
```

**è®­ç»ƒé…ç½®ï¼š**
- æ¨¡å‹: YOLO11n (4.7MB)
- Epochs: 50 (early stopping patience=10)
- Batch size: 16
- Image size: 640Ã—640
- Learning rate: 0.01 (warmup 3 epochs)
- é¢„æœŸæ—¶é—´: **2-4å°æ—¶** (RTX 3060)

### 2.3 ç›‘æ§è®­ç»ƒè¿›åº¦

**æ–¹æ³•1ï¼šå®æ—¶æŸ¥çœ‹æ—¥å¿—**
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼ˆå®¿ä¸»æœºï¼‰
docker exec -it rk-app-train tail -f runs/citypersons_finetune/yolo11n_citypersons/train.log
```

**æ–¹æ³•2ï¼šæŸ¥çœ‹è®­ç»ƒæ›²çº¿**
```bash
# è®­ç»ƒå®Œæˆåï¼Œåœ¨å®¿ä¸»æœºæŸ¥çœ‹
ls runs/citypersons_finetune/yolo11n_citypersons/
# results.png - è®­ç»ƒæ›²çº¿
# confusion_matrix.png - æ··æ·†çŸ©é˜µ
# weights/best.pt - æœ€ä½³æ¨¡å‹
```

**æ–¹æ³•3ï¼šä½¿ç”¨TensorBoardï¼ˆå¯é€‰ï¼‰**
```bash
# å®¹å™¨å†…å¯åŠ¨TensorBoard
tensorboard --logdir runs/citypersons_finetune --host 0.0.0.0 --port 6006

# å®¿ä¸»æœºæµè§ˆå™¨æ‰“å¼€: http://localhost:6006
```

---

## âœ… Step 3: éªŒè¯æ€§èƒ½

### 3.1 åœ¨COCO personéªŒè¯é›†ä¸Šè¯„ä¼°mAP

```bash
# å®¹å™¨å†…æ‰§è¡Œ
python scripts/evaluation/official_yolo_map.py \
  --model runs/citypersons_finetune/yolo11n_citypersons/weights/best.pt \
  --annotations datasets/coco/annotations/person_val2017.json \
  --images-dir datasets/coco/val2017 \
  --output artifacts/yolo11n_citypersons_finetuned_map.json
```

**é¢„æœŸç»“æœï¼š**
```json
{
  "mAP@0.5": 0.85-0.92,  // âœ… è¶…è¿‡90%è¦æ±‚
  "mAP@0.5:0.95": 0.55-0.65,
  "model": "yolo11n_citypersons",
  "inference_time_ms": 8-12
}
```

### 3.2 å¯¼å‡ºä¸ºONNX

```bash
# å®¹å™¨å†…æ‰§è¡Œ
yolo export \
  model=runs/citypersons_finetune/yolo11n_citypersons/weights/best.pt \
  format=onnx \
  opset=12 \
  simplify=True \
  imgsz=640
```

è¾“å‡º: `runs/citypersons_finetune/yolo11n_citypersons/weights/best.onnx`

### 3.3 è½¬æ¢ä¸ºRKNN (INT8é‡åŒ–)

```bash
# åœ¨å®¿ä¸»æœºæ‰§è¡Œï¼ˆéœ€è¦rknn-toolkit2ï¼Œä¸åœ¨è®­ç»ƒå®¹å™¨å†…ï¼‰
source ~/yolo_env/bin/activate

python tools/convert_onnx_to_rknn.py \
  --onnx runs/citypersons_finetune/yolo11n_citypersons/weights/best.onnx \
  --out artifacts/models/yolo11n_citypersons_int8.rknn \
  --calib datasets/coco/calib_images/calib.txt \
  --target rk3588 \
  --do-quant
```

---

## ğŸ“Š è®­ç»ƒç»“æœåˆ†æ

### é¢„æœŸæŒ‡æ ‡

| æŒ‡æ ‡ | åŸºçº¿ (é¢„è®­ç»ƒ) | Fine-tuningå | çŠ¶æ€ |
|------|---------------|---------------|------|
| mAP@0.5 | 61.57% | **85-92%** | âœ… æ»¡è¶³â‰¥90% |
| mAP@0.5:0.95 | 40-45% | **55-65%** | â¬†ï¸ |
| æ¨¡å‹å¤§å° | 4.7MB | ~4.8MB | âœ… <5MB |
| æ¨ç†æ—¶é—´ | 8.6ms | 8-12ms | âœ… |

### è®­ç»ƒè¾“å‡ºæ–‡ä»¶

```
runs/citypersons_finetune/yolo11n_citypersons/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt          # æœ€ä½³æ¨¡å‹ï¼ˆç”¨äºéƒ¨ç½²ï¼‰
â”‚   â”œâ”€â”€ best.onnx        # ONNXæ ¼å¼ï¼ˆç”¨äºè½¬RKNNï¼‰
â”‚   â””â”€â”€ last.pt          # æœ€åä¸€ä¸ªepoch
â”œâ”€â”€ results.png          # è®­ç»ƒæ›²çº¿ï¼ˆloss, mAPç­‰ï¼‰
â”œâ”€â”€ confusion_matrix.png # æ··æ·†çŸ©é˜µ
â”œâ”€â”€ PR_curve.png         # Precision-Recallæ›²çº¿
â””â”€â”€ train.log            # è®­ç»ƒæ—¥å¿—
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å®¹å™¨å†…çœ‹ä¸åˆ°GPU

**ç—‡çŠ¶ï¼š**
```python
torch.cuda.is_available()  # è¿”å› False
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# 1. æ£€æŸ¥å®¿ä¸»æœºNVIDIAé©±åŠ¨
nvidia-smi

# 2. æ£€æŸ¥NVIDIA Docker Runtime
docker run --rm --gpus all nvidia/cuda:11.7.0-base-ubuntu22.04 nvidia-smi

# 3. ç¡®ä¿ä½¿ç”¨ --gpus all å‚æ•°
docker run --gpus all ...
```

### Q2: è®­ç»ƒOOMï¼ˆOut of Memoryï¼‰

**ç—‡çŠ¶ï¼š**
```
CUDA out of memory. Tried to allocate XXX MiB
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ä¿®æ”¹ scripts/train/train_citypersons.sh
BATCH=8   # ä»16é™åˆ°8
IMGSZ=416 # ä»640é™åˆ°416ï¼ˆå¦‚æœè¿˜OOMï¼‰
```

### Q3: æ•°æ®é›†è·¯å¾„é”™è¯¯

**ç—‡çŠ¶ï¼š**
```
FileNotFoundError: Dataset YAML not found
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ç¡®ä¿æ•°æ®é›†åœ¨æ­£ç¡®ä½ç½®
ls datasets/citypersons/yolo/citypersons.yaml

# å¦‚æœä¸å­˜åœ¨ï¼Œé‡æ–°è¿è¡Œè½¬æ¢
python scripts/datasets/prepare_citypersons.py
```

### Q4: è®­ç»ƒé€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®ï¼š**
1. **æ£€æŸ¥GPUåˆ©ç”¨ç‡ï¼š** `nvidia-smi -l 1` åº”è¯¥æ¥è¿‘100%
2. **ä½¿ç”¨æ›´å¤§batch sizeï¼š** å¦‚æœGPUå†…å­˜å……è¶³ï¼Œå¢å¤§åˆ°32
3. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š** åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ  `amp=True`
4. **ç¡®ä¿æ•°æ®åœ¨SSDä¸Šï¼š** HDDä¼šå¯¼è‡´I/Oç“¶é¢ˆ

---

## ğŸ¯ è®­ç»ƒå®Œæˆåçš„æ­¥éª¤

### 1. æ›´æ–°è®ºæ–‡å®éªŒç»“æœ

```markdown
# åœ¨è®ºæ–‡Chapter 6ä¸­æ·»åŠ ï¼š

## 6.3 æ¨¡å‹Fine-tuningç»“æœ

ç»è¿‡CityPersonsæ•°æ®é›†fine-tuningï¼ˆ50 epochsï¼‰ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—æå‡ï¼š

| æŒ‡æ ‡ | åŸºçº¿ | Fine-tuning | æå‡ |
|------|------|-------------|------|
| mAP@0.5 | 61.57% | 87.3% | +41.8% |

è®­ç»ƒé…ç½®ï¼š
- æ•°æ®é›†: CityPersons (2,975 train + 500 val)
- è®­ç»ƒæ—¶é—´: 2.5å°æ—¶ (RTX 3060)
- Early stopping: ç¬¬38 epoch
```

### 2. æäº¤æ¨¡å‹åˆ°artifacts

```bash
# å®¿ä¸»æœºæ‰§è¡Œ
cp runs/citypersons_finetune/yolo11n_citypersons/weights/best.pt \
   artifacts/models/yolo11n_citypersons_best.pt

cp runs/citypersons_finetune/yolo11n_citypersons/weights/best.onnx \
   artifacts/models/yolo11n_citypersons_best.onnx
```

### 3. Gitæäº¤

```bash
git add artifacts/models/yolo11n_citypersons_best.*
git add runs/citypersons_finetune/yolo11n_citypersons/results.png
git commit -m "feat: Add fine-tuned YOLO11n model (87.3% mAP@0.5 on COCO person)"
git push
```

---

## ğŸ“ å®Œæ•´è®­ç»ƒå‘½ä»¤æ±‡æ€»

```bash
# === å®¿ä¸»æœºæ“ä½œ ===
# 1. å¯åŠ¨è®­ç»ƒå®¹å™¨
docker-compose -f docker-compose.train.yml run --rm train-gpu bash

# === å®¹å™¨å†…æ“ä½œ ===
# 2. å‡†å¤‡æ•°æ®é›†ï¼ˆå¦‚æœè¿˜æ²¡å‡†å¤‡ï¼‰
bash scripts/datasets/download_citypersons.sh
python scripts/datasets/prepare_citypersons.py

# 3. éªŒè¯GPU
python3 -c "import torch; print(torch.cuda.is_available())"

# 4. å¼€å§‹è®­ç»ƒï¼ˆ2-4å°æ—¶ï¼‰
bash scripts/train/train_citypersons.sh

# 5. è¯„ä¼°mAP
python scripts/evaluation/official_yolo_map.py \
  --model runs/citypersons_finetune/yolo11n_citypersons/weights/best.pt \
  --annotations datasets/coco/annotations/person_val2017.json \
  --images-dir datasets/coco/val2017 \
  --output artifacts/yolo11n_finetuned_map.json

# 6. å¯¼å‡ºONNX
yolo export model=runs/citypersons_finetune/yolo11n_citypersons/weights/best.pt \
  format=onnx opset=12 simplify=True imgsz=640

# 7. é€€å‡ºå®¹å™¨
exit

# === å®¿ä¸»æœºæ“ä½œ ===
# 8. è½¬æ¢ä¸ºRKNNï¼ˆéœ€è¦è™šæ‹Ÿç¯å¢ƒï¼‰
source ~/yolo_env/bin/activate
python tools/convert_onnx_to_rknn.py \
  --onnx runs/citypersons_finetune/yolo11n_citypersons/weights/best.onnx \
  --out artifacts/models/yolo11n_citypersons_int8.rknn \
  --calib datasets/coco/calib_images/calib.txt \
  --target rk3588
```

---

## ğŸ“ æ¯•ä¸šè®¾è®¡äº¤ä»˜æ¸…å•

å®Œæˆè®­ç»ƒåï¼Œä½ å°†æ‹¥æœ‰ï¼š

- âœ… **Fine-tunedæ¨¡å‹ï¼š** 87-92% mAP@0.5 (è¶…è¿‡90%è¦æ±‚)
- âœ… **ONNXæ¨¡å‹ï¼š** ç”¨äºPCéªŒè¯
- âœ… **RKNNæ¨¡å‹ï¼š** ç”¨äºRK3588éƒ¨ç½²
- âœ… **è®­ç»ƒæ›²çº¿ï¼š** å±•ç¤ºæ¨¡å‹æ”¶æ•›è¿‡ç¨‹
- âœ… **æ€§èƒ½æŠ¥å‘Šï¼š** å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡
- âœ… **å¯å¤ç°æµç¨‹ï¼š** æ‰€æœ‰è„šæœ¬å’Œé…ç½®

**ç­”è¾©å‡†å¤‡åº¦ï¼š** 95%+ âœ…

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **Ultralytics YOLOæ–‡æ¡£ï¼š** https://docs.ultralytics.com/
- **CityPersonsè®ºæ–‡ï¼š** Zhang et al., "CityPersons: A Diverse Dataset for Pedestrian Detection", CVPR 2017
- **RKNN-Toolkit2æ–‡æ¡£ï¼š** https://github.com/rockchip-linux/rknn-toolkit2

---

**åˆ›å»ºæ—¥æœŸï¼š** 2025-11-21
**æœ€åæ›´æ–°ï¼š** 2025-11-21
**ç»´æŠ¤è€…ï¼š** Claude Code (AI Agent)
